<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>4-线性模型--(上) | 朝花夕拾</title><meta name="author" content="TeeyoHuang"><meta name="copyright" content="TeeyoHuang"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="机器学习监督学习涉及的一些知识点">
<meta property="og:type" content="article">
<meta property="og:title" content="4-线性模型--(上)">
<meta property="og:url" content="https://teeyohuang.github.io/Machine-Learning/ML_04_Linear_Model_1.html">
<meta property="og:site_name" content="朝花夕拾">
<meta property="og:description" content="机器学习监督学习涉及的一些知识点">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://teeyohuang.github.io/pic_bed/Machine_Learning/4_1.png">
<meta property="article:published_time" content="2023-05-31T16:04:00.000Z">
<meta property="article:modified_time" content="2024-01-04T14:47:17.503Z">
<meta property="article:author" content="TeeyoHuang">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://teeyohuang.github.io/pic_bed/Machine_Learning/4_1.png"><link rel="shortcut icon" href="/img/favicon_T.png"><link rel="canonical" href="https://teeyohuang.github.io/Machine-Learning/ML_04_Linear_Model_1.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"找不到您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"limitCount":40,"languages":{"author":"作者: TeeyoHuang","link":"链接: ","source":"来源: 朝花夕拾","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  lightbox: 'mediumZoom',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: true,
  }
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '4-线性模型--(上)',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-01-04 22:47:17'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = (url,id = false) => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      if (id) link.id = id
      link.onerror = reject
      link.onload = link.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        link.onload = link.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          const now = new Date()
          const hour = now.getHours()
          const isNight = hour <= 7 || hour >= 22
          if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
          else if (t === 'light') activateLightMode()
          else activateDarkMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="/css/custom.css"><link rel="stylesheet" href="/css/universe.css"><!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-double-row-display@1.00/cardlistpost.min.css"/>
<style>#recent-posts > .recent-post-item >.recent-post-info > .article-meta-wrap > .tags:before {content:"\A";
  white-space: pre;}#recent-posts > .recent-post-item >.recent-post-info > .article-meta-wrap > .tags > .article-meta__separator{display:none}</style>
<link rel="stylesheet" href="/css/runtime.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-wowjs/lib/animate.min.css" media="print" onload="this.media='screen'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiperstyle.css" media="print" onload="this.media='all'"><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/teeyo_comic.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">36</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">0</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">6</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/comments/"><i class="fa-fw fas fa-paper-plane"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于作者</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://teeyohuang.github.io/pic_bed/Machine_Learning/4_1.png')"><nav id="nav"><span id="blog-info"><a href="/" title="朝花夕拾"><span class="site-name">朝花夕拾</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/comments/"><i class="fa-fw fas fa-paper-plane"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于作者</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">4-线性模型--(上)</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-05-31T16:04:00.000Z" title="发表于 2023-06-01 00:04:00">2023-06-01</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-01-04T14:47:17.503Z" title="更新于 2024-01-04 22:47:17">2024-01-04</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Machine-Learning/">机器学习</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">5k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>17分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="4-线性模型--(上)"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><!-- <img src="https://cdn.staticaly.com/gh/teeyohuang/pic_bed@main/img/csdn_head_webp.webp" width=70%>   -->
<p><img src="https://teeyohuang.github.io/pic_bed/img/csdn_head_webp.webp" width="70%"></p>
<hr style="border:solid; height:1px; color=#000000 size=1">  

<h1 id="4-线性模型—-上"><a href="#4-线性模型—-上" class="headerlink" title="4 线性模型—(上)"></a>4 线性模型—(上)</h1><hr style="border:solid; height:1px; color=#000000 size=1">  

<p>之前讲过，<b>如果因变量可以被表示为自变量的线性组合，就能够用线性模型来拟合。</b>线性关系算是日常生活中最常见的关系，比如身高和体重之间，收入和存款之间，年龄和身高之间，等等。所以可从线性模型入手，来学习机器学习。</p>
<h2 id="4-1-线性回归-Linear-Regression"><a href="#4-1-线性回归-Linear-Regression" class="headerlink" title="4.1 线性回归(Linear Regression)"></a>4.1 线性回归(Linear Regression)</h2><h3 id="4-1-1-线性回归模型的引入"><a href="#4-1-1-线性回归模型的引入" class="headerlink" title="4.1.1 线性回归模型的引入"></a>4.1.1 线性回归模型的引入</h3><p>上一章已经介绍了回归任务，目标是预测连续型的数值目标，比如温度、价格等等。而线性回归，就是希望用线性模型，来拟合因变量为连续值的数据，如：儿童的年龄与身高之间的关系、外卖商家的到家的距离和送餐所需时间之间的关系、出租车收费与行驶路程之间的关系…  </p>
<p>我们这里给出一个范例，【外卖配送时间和商家距离】的示例数据：  </p>
<blockquote>
<p><strong>距离</strong>：1.0, 0.0, 2.0, 2.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 9.0, 10.0, 13.0, 14.0, 13.0, 15.0, 16.0, 17.0, 18.0, 18.0, 21.0, 21.0, 21.0, 24.0, 25.0, 24.0, 25.0, 26.0, 27.0, 30.0<br><strong>时间</strong>：20.0, 6.0, 19.0, 25.0, 29.0, 25.0, 33.0, 41.0, 44.0, 44.0, 40.0, 35.0, 52.0, 55.0, 42.0, 53.0, 56.0, 61.0, 67.0, 67.0, 74.0, 71.0, 69.0, 85.0, 90.0, 86.0, 88.0, 86.0, 101.0, 98.0  </p>
</blockquote>
<p>可以画出其散点图：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">dis = [<span class="number">1.0</span>, <span class="number">0.0</span>, <span class="number">2.0</span>, <span class="number">2.0</span>, <span class="number">5.0</span>, <span class="number">6.0</span>, <span class="number">7.0</span>, <span class="number">8.0</span>, <span class="number">9.0</span>, <span class="number">10.0</span>, <span class="number">9.0</span>, <span class="number">10.0</span>, <span class="number">13.0</span>, <span class="number">14.0</span>, <span class="number">13.0</span>, <span class="number">15.0</span>, <span class="number">16.0</span>, <span class="number">17.0</span>, <span class="number">18.0</span>, <span class="number">18.0</span>, <span class="number">21.0</span>, <span class="number">21.0</span>, <span class="number">21.0</span>, <span class="number">24.0</span>, <span class="number">25.0</span>, <span class="number">24.0</span>, <span class="number">25.0</span>, <span class="number">26.0</span>, <span class="number">27.0</span>, <span class="number">30.0</span>]</span><br><span class="line">t = [<span class="number">20.0</span>, <span class="number">6.0</span>, <span class="number">19.0</span>, <span class="number">25.0</span>, <span class="number">29.0</span>, <span class="number">25.0</span>, <span class="number">33.0</span>, <span class="number">41.0</span>, <span class="number">44.0</span>, <span class="number">44.0</span>, <span class="number">40.0</span>, <span class="number">35.0</span>, <span class="number">52.0</span>, <span class="number">55.0</span>, <span class="number">42.0</span>, <span class="number">53.0</span>, <span class="number">56.0</span>, <span class="number">61.0</span>, <span class="number">67.0</span>, <span class="number">67.0</span>, <span class="number">74.0</span>, <span class="number">71.0</span>, <span class="number">69.0</span>, <span class="number">85.0</span>, <span class="number">90.0</span>, <span class="number">86.0</span>, <span class="number">88.0</span>, <span class="number">86.0</span>, <span class="number">101.0</span>, <span class="number">98.0</span>]</span><br><span class="line">plt.figure(figsize=(<span class="number">4</span>, <span class="number">3</span>))</span><br><span class="line">plt.plot(dis,t,<span class="string">&#x27;bo&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;distance/ Km&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;time / min&#x27;</span>)</span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]</span><br><span class="line">plt.title(<span class="string">&#x27;外卖配送时间与商家距离的关系&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></p>
<p><img src="https://teeyohuang.github.io/pic_bed/Machine_Learning/C4_distance_time.jpeg" width="60%"></p>
<p>可以看到，二者的关系近似线性，我们可以尝试用一个如下的线性模型来刻画这样一种线性关系:  </p>
<script type="math/tex; mode=display">h_w(x)  = w x + w_0, \tag{4-1}</script><p>自变量 $x$ 是输入数据，因变量 $y$ 或者$h_w(x)$ 为预测值。</p>
<ul>
<li>$x$ 可以是一个实数，比如在本示例中， $x$ 就代表距离，是一个实数。</li>
<li>$x$ 也可以<b><font color="orangered">是一个多维向量</font></b>(机器学习中说到向量一般都<strong>默认为列向量</strong>): $x=\{ x_1, x_2, \cdots, x_n\}^T$，<strong>其中下标代表的是 $x$ 的维度</strong>。这代表着还有其他维度的因素会影响到回归值，比如在实际生活中，除了距离，还有天气、路况、配送时段等等因素，也可能会影响到外卖的配送时间。这样的话，$x$ 就不止一个值了，就是几个值组成的一个向量，此时被称为<b><font color="orangered">多元线性回归</font></b>。  </li>
</ul>
<p>如果 $x$ 是一个向量，那对应的<strong>列向量</strong> $w$ 就为：$w = \{w_1, w_2, \cdots ,w_n\}^T$; $w$ 在数学上叫作斜率，在线性模型中可以被称为参数：<font color="navy">_Parameter_</font>。更多的时候，我们称它为<strong>权重</strong>：<font color="navy">_Weight_</font>，因为它刻画了它<strong>对应的这个输入特征对于结果的影响力</strong>。其中 $w_0$ 称为截距。  </p>
<p>线性回归最终的目标就是希望能够学习到最合适的 $w$ 参数，来刻画 $y$ 和 $x$ 的关系，<strong>从二维散点图上去理解的话，就是希望找到一条直线，使得散点图中的点，都尽可能的靠近这条直线</strong>。  </p>
<p>如果我们对于输入变量 $x$ 增设一个维度 $x_0 = 1$，去与截距 $w_0$ 相乘，即 $x=\{ 1, x_1, x_2, \cdots, x_n\}^T$，$w = \{w_0, w_1, w_2, \cdots ,w_n\}^T$, 这样就能将式 $(4-1)$ 统一为形式：  </p>
<script type="math/tex; mode=display">h_w(x)  = \sum_{i=0}^n w_i x_i = w^Tx \quad OR \quad x^Tw, \tag{4-2}</script><p>回忆<b><font color="red">统计学习三要素：模型、策略、算法。</font></b>到这里，我们就确定了线性回归问题的三要素中的<strong>模型空间（假设空间）</strong> <font color="orange">$h_w(x)$</font>。  </p>
<h3 id="4-1-2-最小二乘法"><a href="#4-1-2-最小二乘法" class="headerlink" title="4.1.2 最小二乘法"></a>4.1.2 最小二乘法</h3><p><b><font color="red">最小二乘法</font></b>（Least Squares Method，简写为 <b>LS，所以也叫最小平方算法</b>）,是一种数学优化建模方法。<b><font color="orange">它通过最小化误差的平方和 来寻找数据的最佳函数匹配。</font></b>&lt;/font&gt;利用最小二乘法可以简便的求得未知的数据，并使得求得的数据与实际数据之间误差的平方和为最小。  </p>
<p>所以我们依据最小二乘法的策略，使用 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Least_squares">（最小）平方误差 (<font face="Timese" new roman> Least Squares Error, LSE)</font></a> 作为模型的损失函数，（有时候也被叫做最小二乘损失函数）:  </p>
<script type="math/tex; mode=display">J(w) = \sum_{i=1}^m(h_w(x^{(i)})-y^{(i)})^2, \tag{4-3-1}</script><p>上式中的上标 $i$ 指的是第 $i$ 个输入数据，$m$ 代表训练数据的规模，即总共有多少个输入样本。  </p>
<p>下图截取自 Wikipedia：</p>
<p><img src="https://teeyohuang.github.io/pic_bed/Machine_Learning/C4_LSE.jpg" width="80%">  </p>
<p>当所有输入数据预测值与真实值的残差是线性相关的时候，称为<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Ordinary_least_squares">普通最小二乘（ordinary least squares, OLS）</a>。  </p>
<p><img src="https://teeyohuang.github.io/pic_bed/Machine_Learning/C4_OLS_1.jpg" width="80%">  </p>
<p><img src="https://teeyohuang.github.io/pic_bed/Machine_Learning/C4_OLS_2.jpg" width="80%">  </p>
<p>这里，我们就确定了线性回归问题的三要素中的<strong>策略：<font color="orange">最小二乘法</font></strong>。</p>
<h3 id="4-1-3-求解正规方程组"><a href="#4-1-3-求解正规方程组" class="headerlink" title="4.1.3 求解正规方程组"></a>4.1.3 求解正规方程组</h3><p>当面对普通最小二乘问题时，我们采用线性代数的方法，对参数值进行直接求解估算。这里用到的就是：<strong>正规方程组</strong> <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Ordinary_least_squares#Normal_equations"><font face="Times" new roman>Normal Equations</font></a>。  </p>
<p>首先，将 $m$ 个输入数据 $x$ 合在一起用矩阵 $X$ 表达, 并且将对应的 $m$ 个标签 $y$ 值合在一起用向量 $\vec{y}$ 表示：  </p>
<script type="math/tex; mode=display">
X=
\begin{bmatrix}
-(x^{(1)})^T-  \\
-(x^{(2)})^T-  \\
\vdots      \\
-(x^{(m)})^T- 
\end{bmatrix},
\quad\quad\quad\vec{y} = 
\begin{bmatrix}
y^{(1)} \\
y^{(2)} \\
\vdots \\
y^{(m)}
\end{bmatrix}, \tag{4-4-1}</script><p>注意，$ x^{(i)} $ 本身是列向量，所以 $ (x^{(i)})^T $ 是行向量。  </p>
<p>$w$ 仍为：  $w = \{w_0, w_1, w_2, \cdots ,w_n\}^T$</p>
<p>损失函数(3-1)就可以写为：  </p>
<script type="math/tex; mode=display">J(w) = ||Xw-\vec{y}||^2 = (Xw-\vec{y})^T(Xw-\vec{y}), \tag{4-4-2}</script><p>当式(4-4-2)的损失函数最小的时候，$ w $ 就是最优的参数值。那么令损失函数的导数 $\frac{\partial J(w)}{\partial w}=0 $ 时，损失函数就能取得极值，此时：</p>
<script type="math/tex; mode=display">
\frac{\partial J(w)}{\partial w}=X^TXw-X^T\vec{y} =0, \tag{4-4-3}</script><p>得 :  </p>
<script type="math/tex; mode=display">X^T \vec{y} = X^T Xw, \tag{4-4-4}</script><p>式(4-4-3)就被称为<b><font color="red">正规方程组</font></b>。之所以要这么变换，是因为 $ (X^T X)$一定是方阵，要求逆矩阵，必要条件是方阵。 </p>
<p>$ (X^T X)$ 被称为<b>正规矩阵（normal matrix）</b>或者<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Gram_matrix">格拉姆矩阵（Gram matrix）</a>。<b>如果 $X$ 中的行向量彼此线性独立，能够推出格拉姆矩阵行列式不为0，即存在逆矩阵。<font color="navy"> 即训练样本彼此线性独立的话，（<a target="_blank" rel="noopener" href="https://baike.baidu.com/item/%E5%A4%9A%E9%87%8D%E5%85%B1%E7%BA%BF%E6%80%A7">不存在多重共线性</a>），其特征向量构成的格拉姆矩阵就是可逆的。</font></b></p>
<p>等式两边同时左乘以 $ (X^T X)$ 的逆 $ (X X^T)^{-1} $ 得:</p>
<script type="math/tex; mode=display">w = 
\begin{bmatrix}
w_0 \\
w_1 \\
\vdots \\
w_n
\end{bmatrix}
=(XX^T)^{-1}X^T\vec{y}, \tag{4-5}</script><p>至此，机器学习三要素中的最后一个<b>算法</b>也确定了，<b><font color="orange">用正规方程组求解参数</font>。</b>   </p>
<p>使用线性回归模型对示例数据进行拟合后，结果如下图所示：  </p>
<p><img src="https://teeyohuang.github.io/pic_bed/Machine_Learning/C4_result_1.jpg" width="80%"> <br>  </p>
<h3 id="4-1-4-最小均方算法"><a href="#4-1-4-最小均方算法" class="headerlink" title="4.1.4 最小均方算法"></a>4.1.4 最小均方算法</h3><h4 id="4-1-4-1-最小均方算法的定义"><a href="#4-1-4-1-最小均方算法的定义" class="headerlink" title="4.1.4.1 最小均方算法的定义"></a>4.1.4.1 最小均方算法的定义</h4><p><b>最小均方算法（Least Mean Square，简称为LMS）</b>在互联网上经常和 <b>最小平方算法（即最小二乘法，Least Square，简称为LS）</b>混为一谈，其实它们是两个不同的算法，但是确实又在某些方面很相似，极容易混淆。所以这里补充讲解一下，简单的来说一下二者的联系和区别。  </p>
<p>首先要明确的一点，是<b>LMS</b>方法和<b>LS</b>方法都是属于机器学习三要素中的<b>策略</b>这一部分，即<b>依据怎样的准则选择最优的参数</b>。 </p>
<font color="red">最小均方算法的起源是1960年代，由Widrow和Hoff在<b>自适应滤波器领域</b>提出的一种优化算法，他们希望找到一种可以<b>自动调整权重以最小化输出误差的方法</b>。他们提出的最小均方滤波器(Least Mean Square Filter)如下所示</font>：  

<img src="https://teeyohuang.github.io/pic_bed/Machine_Learning/C4_LMS_1.jpg" width="50%">  

图中变量说明：  
- $ x(n) 是输入信号脉冲 $  
- $ h(n) 一个未知的滤波系统（就是待求解的滤波器） $    
- $ y(n) 是未知滤波系统的输出信号脉冲 $    
- $ v(n) 是噪音 $   
- $ d(n) = y(n) + v(n) $  
- $ \hat{h}(n) 是自适应滤波器（目的就是期望通过这个自适应滤波器来模拟待求解滤波器） $ 
- $ \hat{y}(n) 是自适应滤波器的输出 $  
- $ e(n) = d(n) - \hat{y}(n) 两个滤波器的输出差异 $  

<font color="navy">以机器学习的角度来看，$ x(n) $ 就是输入样本，$ y(n) $ 就是输入对应的真实标签(label);  
现在希望能够构建一个模型 $ \hat{h}(n) $ 来拟合这个真实的未知系统 $ h(n) $，然后 $ \hat{y}(n) $ 就是模型的预测输出。  
而学习的策略就是使得对于每一个输入信号脉冲 $ x(n) $，预测输出脉冲 $ \hat{y}(n) $ 与 真实系统输出脉冲 $ y(n) $  的误差平方值最小。</font>  

<p><b>而显然，仅仅输入一次信号，是无法准确的拟合一个未知滤波系统，所以需要多次输入信号，然后不断调整自适应滤波器的参数，使得输出的误差平方值最小。</b>  </p>
<p><b>所以，如果对于这个系统，<font color="OrangeRed">后续每一次的输入信号，都使得这一次输出的误差平方值最小，就说明自适应滤波器 $ \hat{h}(n) $ 已经能够较好的拟合未知系统 $ h(n) $ 了</font>。这就是最小均方算法（Least Mean Square）</b>。  </p>
<p>从这里就能知道，<font color="OrangeRed">最小均方算法 (Least Mean Square) 中的 <b>均</b>本来指的是<b>期望&lt;/b &gt;，而不是简单的算术平均值</b></font>。  </p>
<ul>
<li>图一：<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Least_mean_squares_filter#Derivation">LMS filter</a> 定义(from Wikipedia)  </li>
</ul>
<p><img src="https://teeyohuang.github.io/pic_bed/Machine_Learning/C4_LMS_2.jpg" width="100%"><br>  </p>
<ul>
<li>图二：<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Expected_value">Expected Value</a>定义(from Wikipedia)<br>在统计学中，期望(Expected Value)有时候也会被称为均值(Mean)。  </li>
</ul>
<p><img src="https://teeyohuang.github.io/pic_bed/Machine_Learning/C4_LMS_3.jpg" width="85%">  </p>
<p>从现实情况入手分析，因为输入脉冲信号是一个接一个出现并通过滤波器的，在输入信号到来之前，是不知道该输入信号具体的情况的！<font color="orangered">所以只能通过<b>一次又一次的迭代调整参数</b>，最小化<b>期望平均误差</b>。 即希望 预测输出信号与滤波器实际输出 之差 的平方值，每一次都达到最小，从统计学的角度来看，就是误差平方变量 $ |e(n)|^2 $ 的期望值越小越好</font>。  </p>
<h4 id="4-1-4-2-最小均方算法与最小平方算法的区别"><a href="#4-1-4-2-最小均方算法与最小平方算法的区别" class="headerlink" title="4.1.4.2 最小均方算法与最小平方算法的区别"></a>4.1.4.2 最小均方算法与最小平方算法的区别</h4><p>从上面最小均方算法的原始起源可以看出，其学习过程可以视为机器学习中的<b>在线学习(online-learning)</b>：每当一份新的样本数据到来时就进行一次训练，而不需要等到所有的数据都集齐后再统一进行训练。  </p>
<p>其损失函数为<b>均方误差(Mean Square Error)</b>:  </p>
<script type="math/tex; mode=display">J(w) = E[(h_w(x^{(i)})-y^{(i)})^2], \tag{4-6-1}</script><p>即希望对所有样本输出误差的平方的期望值最小，关于均方误差(MSE)，在 4.1.5.1 小节会更为详细探讨。  </p>
<p>而<b>最小平方算法(Least Square)</b> 是对于<b>所有训练样本</b>而言，每个样本对应的预测输出值与标签的<b>差值的平方的<font color="orangered">总和</font></b> 最小，是典型的<b>离线学习</b>：将所有的数据收集齐后，再进行一次性训练。</p>
<p>其损失函数为<b>平方误差(Square Error)，上面式(4-3-1)已经给出：</b>  </p>
<script type="math/tex; mode=display">J(w) = \sum_{i=1}^m(h_w(x^{(i)})-y^{(i)})^2, \tag{4-3-1}</script><h4 id="4-1-4-3-随机梯度下降-Stochastic-Gradient-Descent"><a href="#4-1-4-3-随机梯度下降-Stochastic-Gradient-Descent" class="headerlink" title="4.1.4.3 随机梯度下降(Stochastic Gradient Descent)"></a>4.1.4.3 随机梯度下降(Stochastic Gradient Descent)</h4><p>对于LMS优化算法，其每一次都只处理一个样本，所以损失函数在<b>对于一个具体的样本而言</b>，形式为：  </p>
<script type="math/tex; mode=display">J(w) = \frac{1}{2}(h_w(x^{(i)})-y^{(i)})^2, \tag{4-6-2}</script><p>即计算当<b>前预测输出和标签的差值的平方</b>，之所以在前方多了一个 $\frac{1}{2}$ 是为了后续求导时方便计算，<b>这里多乘一个常量系数，只会缩放损失值的幅度，是不会对模型参数的优化结果产生影响的</b>。  </p>
<p>对于这个损失函数，如何来选择参数 $ w $ 来使得损失函数值最小呢？  </p>
<p>在高等数学的微积分中我们已经学过：<b>函数在一点<font color="orangered">沿梯度方向的变化率最大</font>，最大值为该梯度的模。<font color="orangered">也就是说，顺着梯度方向，函数值增加的最快；逆着梯度方向，函数值减小的最快。</font></b>  </p>
<p>如图所示，假设我们从一个山坡的顶部想要下降到山底，那么根本不需要四处去试探，只需要沿着山体的最陡峭的方向往下走，我们下降的速度是最快的。而对于函数而言，其梯度方向就是陡的方向。  </p>
<p><img src="https://teeyohuang.github.io/pic_bed/Machine_Learning/C4_SGD_1.jpg" width="85%">  </p>
<p>只要将参数 $ w $ 沿着负梯度方向进行更新，即<b>每一次使得 $ w $ 向负梯度方向变化一小点，那么损失函数值也就能一点一点的变小</b>，最终到达一个局部极小值，这个局部极小值可能并不是全局最小值，如下图所示另一个局部极小值情况。但是基本上也是一个很小的值了，这一点就不是本优化算法要探讨的问题了。  </p>
<p><img src="https://teeyohuang.github.io/pic_bed/Machine_Learning/C4_SGD_3.jpg" width="50%">   </p>
<p>这种优化参数的算法，被称为梯度下降算法(Gradient Descent)，附录中有对其更为详细的描述。<b>如果每一次更新参数时，<font color="orangered">只考虑一个样本</font>，就被更具体的称为随机梯度下降算法(Stochastic Gradient Descent)</b>。  </p>
<p>而LMS算法（策略），其参数优化算法就是采用的随机梯度下降算法(SGD)，具体操作如下：  </p>
<p>先对损失函数求导  </p>
<script type="math/tex; mode=display">\begin{aligned} 
\frac{\partial J(w)}{\partial w} &= \frac{\partial \frac{1}{2}(h_w(x^{(i)})-y^{(i)})^2}{\partial w} \\
 &= (h_w(x^{(i)})-y^{(i)}) \frac{\partial(h_w(x^{(i)})-y^{(i)})}{\partial w} \\
 &= (h_w(x^{(i)})-y^{(i)}) \frac{\sum_{j=1}^n w_j x_j^{(i)} - y^{(i)}}{\partial w} 
\end{aligned}, 
\tag{4-7-1}</script><p>其中 $x_j^{(i)}$ 为第 $i$ 个样本的第 $j$ 个特征值， $y^{(i)}$ 表示第 $i$ 个样本的标签值。<br><b>另外，LMS自适应滤波器是一个线性滤波器，所以可以用上面提到的线性模型 $h_w(x^{(i)}) = w^Tx^{(i)}$ 表示</b>。  </p>
<p>所以对于参数 $w = \{w_1, w_2, \cdots , w_j ,\cdots， w_n\}^T$ 而言，其各个维度 $w_j$ 具体的梯度分量表达式就为： </p>
<script type="math/tex; mode=display">\begin{aligned} 
\frac{\partial J(w)}{\partial w_j} &= (h_w(x^{(i)})-y^{(i)}) \frac{\sum_{j=1}^n w_j x_j^{(i)} - y^{(i)}}{\partial w_j} \\
&= (h_w(x^{(i)})-y^{(i)}) x_j^{(i)}
\end{aligned}, 
\tag{4-7-2}</script><p>所以，每一次对于该权重参数分量 $ w_j $ 的更新公式就为：  </p>
<script type="math/tex; mode=display">w_j := w_j - \alpha (h_w(x^{(i)})-y^{(i)}) x_j^{(i)} , \tag{4-7-3}</script><p><b>其中 $\alpha$ 为学习率，是一个超参数，控制每一次迭代更新参数的一个幅度</b>；也就是理解为下坡的时候，一步跨多远的距离，所以也被称为“步长”。 学习率过小的话，则需要迭代很多次才能收敛，学习率过大，则可能出现震荡，甚至发散。  </p>
<p>如果将括号内的式子的顺序改一下，式（4-7-3）也可以写为：  </p>
<script type="math/tex; mode=display">w_j := w_j + \alpha (y^{(i)} - h_w(x^{(i)})) x_j^{(i)} , \tag{4-7-4}</script><p><b>总结起来，最小均方算法(LMS)就是利用随机梯度下降算法，每次都利用当前一个样本的数据，来更新参数</b>。  </p>
<h3 id="4-1-5-最小均方算法-LMS-和最小平方算法-LS-的联系"><a href="#4-1-5-最小均方算法-LMS-和最小平方算法-LS-的联系" class="headerlink" title="4.1.5 最小均方算法(LMS)和最小平方算法(LS)的联系"></a>4.1.5 最小均方算法(LMS)和最小平方算法(LS)的联系</h3><ul>
<li><p>二者都是可以用来拟合线性模型的  </p>
<blockquote>
<p>在使用这两种算法时，我们模型的假设空间都是设为 </p>
<script type="math/tex; mode=display">h_w(x)  = \sum_{i=0}^n w_i x_i = w^Tx \quad OR \quad x^Tw</script><p>即线性模型。  </p>
</blockquote>
</li>
<li><p>二者的损失函数都要计算平方差：  </p>
<blockquote>
<script type="math/tex; mode=display">(h_w(x^{(i)})-y^{(i)})^2</script><p>只不过LS算法是要计算全部训练集的 平方差之和；<br>而LMS算法是每次只利用一个样本的 平方差来更新参数。  </p>
</blockquote>
</li>
<li><p>能够用最小平方算法(LS)拟合的模型，往往也能用最小均方算法(LMS)拟合。<br>反之，不一定。  </p>
<blockquote>
<p>因为能够使用LS算法时，其训练集是已知的。如果我们在使用训练集的时候，采用在线学习的方法，一次只使用一个样本，并使用SGD算法来更新参数，那么实际上我们就是在使用LMS算法了。<br><br>但是这一般要求训练集是足够大的。因为依据<b>辛钦大数定律</b>，当样本个数足够大时，样本 $(X_1, X_2, \cdots, X_n)$ 的<b>算术平均值</b>依概率收敛于总体<b>数学期望</b>$ E(X)$。 </p>
</blockquote>
</li>
</ul>
<h4 id="4-1-5-1-均方误差-Mean-Squared-Error"><a href="#4-1-5-1-均方误差-Mean-Squared-Error" class="headerlink" title="4.1.5.1 均方误差(Mean Squared Error)"></a>4.1.5.1 均方误差(Mean Squared Error)</h4><p>维基百科中对 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Mean_squared_error">均方误差(MSE)</a> 的定义：  </p>
<p><img src="https://teeyohuang.github.io/pic_bed/Machine_Learning/C4_MSE_1.jpg" width="90%">  </p>
<p>重点看一下这两句话： </p>
<blockquote>
<p>“MSE is a risk function, corresponding to the expected value of the squared error loss.”  </p>
<p>MSE是一个风险函数，对应于误差损失平方的期望值。  </p>
<p>“In machine learning, specifically empirical risk minimization, MSE may refer to the empirical risk (the average loss on an observed data set), as an estimate of the true MSE (the true risk: the average loss on the actual population distribution).”  </p>
<p>在机器学习中，特别是经验风险最小化，MSE可以将经验风险(观察数据集上的平均损失)作为真MSE(真风险:实际总体分布上的平均损失)的估计。</p>
</blockquote>
<p>也就是说，<font color="orangered">均方误差(MSE)的原始定义就是：误差的平方的<b>期望值</b></font>。 事实上，维基百科对于该词条的中文介绍也写明了，只不过中文介绍一般内容比较简略，所以我通常直接引用的是如上的英文版。  </p>
<p><img src="https://teeyohuang.github.io/pic_bed/Machine_Learning/C4_MSE_2.jpg" width="100%"> <br>  </p>
<p>但是，期望值一般都是一个统计学上的概念，对于实际的机器学习来说，一般是比较难求基于训练集的输出误差期望值的，<b>所以一般也可以用基于整个训练集的误差平方和的算数平均值来近似代替。</b>  </p>
<p>所以在很多地方通常都能看到用如下表达式来表示均方误差(MSE)：  </p>
<script type="math/tex; mode=display">J(w) = \frac{1}{m}\sum_{i=1}^m(h_w(x^{(i)})-y^{(i)})^2, \tag{4-8}</script><p>即平方误差(式4-3)的基础上多了一个求平均 $\frac{1}{m}$ 而已。但是一定要注意，这只是在确定能够全部获得m个样本的情况下才能用。Wikipedia也有这种表示情况：  </p>
<p><img src="https://teeyohuang.github.io/pic_bed/Machine_Learning/C4_MSE_3.jpg" width="100%"> <br>  </p>
<p>它称其为<b>样本内均方误差(within-sample MSE)</b>。  </p>
<font color="orangered">所以当训练集的样本是<b>有限的、且确定、且样本规模足够大</b>(辛钦大数定律)的情况下，均方误差(MSE)的确实可以写成式（4-8）的形式</font>。  


<font color="red">另外还有一个不容易注意到的点，那就是英文中的 <b>mean</b> 一词，它既可以表示<b>[算术平均值(Arithmetic mean)](https://en.wikipedia.org/wiki/Arithmetic_mean)</b>，也可以表示<b>[总体均值 or 期望(Population mean or Expected value,)](https://en.wikipedia.org/wiki/Statistical_population#Mean)</b>, 所以这也是很多中文机器学习书籍中容易引起混淆的原因。</font>  

<font color="navy">总结：依据最小均方算法(LMS)的起源，均方误差(MSE)原始定义是<b>误差的平方的期望值</b>，在机器学习里，通常用<b>样本内均方误差(within-sample MSE)或者说误差平方和的平均值来近似代替</b>。</font>







</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="https://Teeyohuang.github.io">TeeyoHuang</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://teeyohuang.github.io/Machine-Learning/ML_04_Linear_Model_1.html">https://teeyohuang.github.io/Machine-Learning/ML_04_Linear_Model_1.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://Teeyohuang.github.io" target="_blank">朝花夕拾</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="https://teeyohuang.github.io/pic_bed/Machine_Learning/4_1.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/Machine-Learning/ML_03_Supervised_Learning_Introduction.html" title="3-监督学习简述"><img class="cover" src="https://teeyohuang.github.io/pic_bed/Machine_Learning/3_0.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">3-监督学习简述</div></div></a></div><div class="next-post pull-right"><a href="/Pandas-Base/PD_01_Introduction.html" title="1-Pandas教程简介"><img class="cover" src="https://teeyohuang.github.io/pic_bed/Pandas_Base/1_0.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">1-Pandas教程简介</div></div></a></div></nav><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/teeyo_comic.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">TeeyoHuang</div><div class="author-info__description">『Stay Hungry. Stay Foolish.』</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">36</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">6</div></a></div><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/teeyohuang" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="/teeyohuang@163.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog, just for recording and sharing.</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#4-%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B%E2%80%94-%E4%B8%8A"><span class="toc-text">4 线性模型—(上)</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#4-1-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92-Linear-Regression"><span class="toc-text">4.1 线性回归(Linear Regression)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-1-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%BC%95%E5%85%A5"><span class="toc-text">4.1.1 线性回归模型的引入</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-2-%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95"><span class="toc-text">4.1.2 最小二乘法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-3-%E6%B1%82%E8%A7%A3%E6%AD%A3%E8%A7%84%E6%96%B9%E7%A8%8B%E7%BB%84"><span class="toc-text">4.1.3 求解正规方程组</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-4-%E6%9C%80%E5%B0%8F%E5%9D%87%E6%96%B9%E7%AE%97%E6%B3%95"><span class="toc-text">4.1.4 最小均方算法</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#4-1-4-1-%E6%9C%80%E5%B0%8F%E5%9D%87%E6%96%B9%E7%AE%97%E6%B3%95%E7%9A%84%E5%AE%9A%E4%B9%89"><span class="toc-text">4.1.4.1 最小均方算法的定义</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-1-4-2-%E6%9C%80%E5%B0%8F%E5%9D%87%E6%96%B9%E7%AE%97%E6%B3%95%E4%B8%8E%E6%9C%80%E5%B0%8F%E5%B9%B3%E6%96%B9%E7%AE%97%E6%B3%95%E7%9A%84%E5%8C%BA%E5%88%AB"><span class="toc-text">4.1.4.2 最小均方算法与最小平方算法的区别</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-1-4-3-%E9%9A%8F%E6%9C%BA%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D-Stochastic-Gradient-Descent"><span class="toc-text">4.1.4.3 随机梯度下降(Stochastic Gradient Descent)</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-5-%E6%9C%80%E5%B0%8F%E5%9D%87%E6%96%B9%E7%AE%97%E6%B3%95-LMS-%E5%92%8C%E6%9C%80%E5%B0%8F%E5%B9%B3%E6%96%B9%E7%AE%97%E6%B3%95-LS-%E7%9A%84%E8%81%94%E7%B3%BB"><span class="toc-text">4.1.5 最小均方算法(LMS)和最小平方算法(LS)的联系</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#4-1-5-1-%E5%9D%87%E6%96%B9%E8%AF%AF%E5%B7%AE-Mean-Squared-Error"><span class="toc-text">4.1.5.1 均方误差(Mean Squared Error)</span></a></li></ol></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/Pandas-Base/PD_07_Pandas_Senior_Data_Operations.html" title="7-pandas数据分组聚合合并"><img src="https://teeyohuang.github.io/pic_bed/Pandas_Base/7_0.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="7-pandas数据分组聚合合并"/></a><div class="content"><a class="title" href="/Pandas-Base/PD_07_Pandas_Senior_Data_Operations.html" title="7-pandas数据分组聚合合并">7-pandas数据分组聚合合并</a><time datetime="2023-10-31T16:06:00.000Z" title="发表于 2023-11-01 00:06:00">2023-11-01</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/Pandas-Base/PD_06_Pandas_Medior_Data_Operations.html" title="6-pandas数据进阶操作"><img src="https://teeyohuang.github.io/pic_bed/Pandas_Base/6_0.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="6-pandas数据进阶操作"/></a><div class="content"><a class="title" href="/Pandas-Base/PD_06_Pandas_Medior_Data_Operations.html" title="6-pandas数据进阶操作">6-pandas数据进阶操作</a><time datetime="2023-10-31T16:05:00.000Z" title="发表于 2023-11-01 00:05:00">2023-11-01</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/Pandas-Base/PD_05_Pandas_Junior_Data_Operations.html" title="5-pandas数据基础操作"><img src="https://teeyohuang.github.io/pic_bed/Pandas_Base/5_0.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="5-pandas数据基础操作"/></a><div class="content"><a class="title" href="/Pandas-Base/PD_05_Pandas_Junior_Data_Operations.html" title="5-pandas数据基础操作">5-pandas数据基础操作</a><time datetime="2023-10-31T16:04:00.000Z" title="发表于 2023-11-01 00:04:00">2023-11-01</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2023 - 2024 By TeeyoHuang</div><div class="footer_custom_text">Hi, welcome to my <a target="_blank" rel="noopener" href="https://butterfly.js.org/">blog</a>!</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/medium-zoom/dist/medium-zoom.min.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.1
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container').forEach(node => {
            if (node.hasAttribute('display')) {
              btf.wrap(node, 'div', { class: 'mathjax-overflow' })
            } else {
              btf.wrap(node, 'span', { class: 'mathjax-overflow' })
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typesetPromise()
}</script><script>function loadValine () {
  function initValine () {
    const valine = new Valine(Object.assign({
      el: '#vcomment',
      appId: 'HgAn8i4mE43FcGFWsenlAi1P-gzGzoHsz',
      appKey: 'KUQAsQXyj2wWidCEzHg4ds1i',
      avatar: 'monsterid',
      serverURLs: '',
      emojiMaps: "",
      path: window.location.pathname,
      visitor: false
    }, null))
  }

  if (typeof Valine === 'function') initValine() 
  else getScript('https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js').then(initValine)
}

if ('Valine' === 'Valine' || !true) {
  if (true) btf.loadComment(document.getElementById('vcomment'),loadValine)
  else setTimeout(loadValine, 0)
} else {
  function loadOtherComment () {
    loadValine()
  }
}</script></div><canvas id="universe"></canvas><script defer src="/js/universe.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = true;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div class="no-result" id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div><!-- hexo injector body_end start --> <script data-pjax>if(document.getElementById('recent-posts') && (location.pathname ==='/'|| '/' ==='all')){
    var parent = document.getElementById('recent-posts');
    var child = '<div class="recent-post-item" style="width:100%;height: auto"><div id="catalog_magnet"><div class="magnet_item"><a class="magnet_link" href="https://Teeyohuang.github.io/categories/Data-Structure/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🎮 数据结构与算法 (17)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://Teeyohuang.github.io/categories/Machine-Learning/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📚 机器学习 (6)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://Teeyohuang.github.io/categories/Deep-Learning/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">👩‍💻 深度学习 (5)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://Teeyohuang.github.io/categories/Computer-Vision/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📒 计算机视觉 (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://Teeyohuang.github.io/categories/Pandas-Base/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">💡 Pandas基础入门 (7)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item" style="visibility: hidden"></div><a class="magnet_link_more"  href="https://Teeyohuang.github.io/categories" style="flex:1;text-align: center;margin-bottom: 10px;">查看更多...</a></div></div>';
    console.log('已挂载magnet')
    parent.insertAdjacentHTML("afterbegin",child)}
     </script><style>#catalog_magnet{flex-wrap: wrap;display: flex;width:100%;justify-content:space-between;padding: 10px 10px 0 10px;align-content: flex-start;}.magnet_item{flex-basis: calc(33.333333333333336% - 5px);background: #f2f2f2;margin-bottom: 10px;border-radius: 8px;transition: all 0.2s ease-in-out;}.magnet_item:hover{background: #cad6d9}.magnet_link_more{color:#555}.magnet_link{color:black}.magnet_link:hover{color:white}@media screen and (max-width: 600px) {.magnet_item {flex-basis: 100%;}}.magnet_link_context{display:flex;padding: 10px;font-size:16px;transition: all 0.2s ease-in-out;}.magnet_link_context:hover{padding: 10px 20px;}</style>
    <style></style><script data-pjax>
  function butterfly_footer_beautify_injector_config(){
    var parent_div_git = document.getElementById('footer-wrap');
    var item_html = '<div id="workboard"></div><p id="ghbdages"><a class="github-badge" target="_blank" href="https://hexo.io/" style="margin-inline:5px" data-title="博客框架为Hexo" title=""><img src="https://img.shields.io/badge/Frame-Hexo-blue?style=flat&amp;logo=hexo" alt=""/></a><a class="github-badge" target="_blank" href="https://butterfly.js.org/" style="margin-inline:5px" data-title="主题版本Butterfly" title=""><img src="https://img.shields.io/badge/Theme-Butterfly-6513df?style=flat&amp;logo=bitdefender" alt=""/></a><a class="github-badge" target="_blank" href="https://github.com/" style="margin-inline:5px" data-title="本站项目由Github托管" title=""><img src="https://img.shields.io/badge/Source-Github-d021d6?style=flat&amp;logo=GitHub" alt=""/></a><a class="github-badge" target="_blank" href="http://creativecommons.org/licenses/by-nc-sa/4.0/" style="margin-inline:5px" data-title="本站采用知识共享署名-非商业性使用-相同方式共享4.0国际许可协议进行许可" title=""><img src="https://img.shields.io/badge/Copyright-BY--NC--SA%204.0-d42328?style=flat&amp;logo=Claris" alt=""/></a></p>';
    console.log('已挂载butterfly_footer_beautify')
    parent_div_git.insertAdjacentHTML("beforeend",item_html)
    }
  var elist = 'null'.split(',');
  var cpage = location.pathname;
  var epage = 'all';
  var flag = 0;

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_footer_beautify_injector_config();
  }
  else if (epage === cpage){
    butterfly_footer_beautify_injector_config();
  }
  </script><script async src="/js/runtime.js"></script><div class="js-pjax"><script async="async">var arr = document.getElementsByClassName('recent-post-item');
for(var i = 0;i<arr.length;i++){
    arr[i].classList.add('wow');
    arr[i].classList.add('animate__zoomIn');
    arr[i].setAttribute('data-wow-duration', '2s');
    arr[i].setAttribute('data-wow-delay', '1s');
    arr[i].setAttribute('data-wow-offset', '100');
    arr[i].setAttribute('data-wow-iteration', '2');
  }</script><script async="async">var arr = document.getElementsByClassName('card-widget');
for(var i = 0;i<arr.length;i++){
    arr[i].classList.add('wow');
    arr[i].classList.add('animate__zoomIn');
    arr[i].setAttribute('data-wow-duration', '');
    arr[i].setAttribute('data-wow-delay', '');
    arr[i].setAttribute('data-wow-offset', '');
    arr[i].setAttribute('data-wow-iteration', '');
  }</script><script async="async">var arr = document.getElementsByClassName('pagination');
for(var i = 0;i<arr.length;i++){
    arr[i].classList.add('wow');
    arr[i].classList.add('animate__zoomIn');
    arr[i].setAttribute('data-wow-duration', '');
    arr[i].setAttribute('data-wow-delay', '');
    arr[i].setAttribute('data-wow-offset', '');
    arr[i].setAttribute('data-wow-iteration', '');
  }</script></div><script defer src="https://npm.elemecdn.com/hexo-butterfly-wowjs/lib/wow.min.js"></script><script defer src="https://npm.elemecdn.com/hexo-butterfly-wowjs/lib/wow_init.js"></script><script data-pjax>
  function butterfly_swiper_injector_config(){
    var parent_div_git = document.getElementById('recent-posts');
    var item_html = '<div class="recent-post-item" style="height: auto;width: 100%"><div class="blog-slider swiper-container-fade swiper-container-horizontal" id="swiper_container"><div class="blog-slider__wrp swiper-wrapper" style="transition-duration: 0ms;"><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="Machine-Learning/ML_00_Introduction.html" alt=""><img width="48" height="48" src="https://teeyohuang.github.io/pic_bed/Machine_Learning/0_0.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-06-01</span><a class="blog-slider__title" href="Machine-Learning/ML_00_Introduction.html" alt="">机器学习系列</a><div class="blog-slider__text">机器学习系列文章简介</div><a class="blog-slider__button" href="Machine-Learning/ML_00_Introduction.html" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="Data-Structure/DS_00_introduction.html" alt=""><img width="48" height="48" src="https://teeyohuang.github.io/pic_bed/Data_Structure/Data_Structure_and_Algorithm_webp.webp" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-04-29</span><a class="blog-slider__title" href="Data-Structure/DS_00_introduction.html" alt="">数据结构与算法_Python</a><div class="blog-slider__text">数据结构与算法_Python 系列专栏简要说明</div><a class="blog-slider__button" href="Data-Structure/DS_00_introduction.html" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="Pandas-Base/PD_01_Introduction.html" alt=""><img width="48" height="48" src="https://teeyohuang.github.io/pic_bed/Pandas_Base/1_0.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-11-01</span><a class="blog-slider__title" href="Pandas-Base/PD_01_Introduction.html" alt="">1-Pandas教程简介</a><div class="blog-slider__text">Pandas基础入门系列文章简介</div><a class="blog-slider__button" href="Pandas-Base/PD_01_Introduction.html" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="Deep-Learning/DL_00_introduction.html" alt=""><img width="48" height="48" src="https://teeyohuang.github.io/pic_bed/Deep_Learning/DL.webp" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-05-01</span><a class="blog-slider__title" href="Deep-Learning/DL_00_introduction.html" alt="">深度学习导论</a><div class="blog-slider__text">深度学习 系列专栏简要说明</div><a class="blog-slider__button" href="Deep-Learning/DL_00_introduction.html" alt="">详情   </a></div></div></div><div class="blog-slider__pagination swiper-pagination-clickable swiper-pagination-bullets"></div></div></div>';
    console.log('已挂载butterfly_swiper')
    parent_div_git.insertAdjacentHTML("afterbegin",item_html)
    }
  var elist = 'undefined'.split(',');
  var cpage = location.pathname;
  var epage = 'all';
  var flag = 0;

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_swiper_injector_config();
  }
  else if (epage === cpage){
    butterfly_swiper_injector_config();
  }
  </script><script defer src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.js"></script><script defer data-pjax src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper_init.js"></script><!-- hexo injector body_end end --></body></html>